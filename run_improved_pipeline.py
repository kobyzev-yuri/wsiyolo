#!/usr/bin/env python3
"""
–ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ WSI YOLO Pipeline —Å –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
"""

import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent / "src"))

from improved_wsi_yolo_pipeline import ImprovedWSIYOLOPipeline

def main():
    """–ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ pipeline —Å –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    print("üöÄ –ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ WSI YOLO Pipeline")
    print("=" * 60)
    
    # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º
    model_paths = {
        'lp': 'models/lp.pt',
        'mild': 'models/mild.pt',
        'moderate': 'models/moderate.pt'
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–µ–π
    missing_models = []
    for model_name, model_path in model_paths.items():
        if not os.path.exists(model_path):
            missing_models.append(f"{model_name}: {model_path}")
    
    if missing_models:
        print("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –º–æ–¥–µ–ª–∏:")
        for missing in missing_models:
            print(f"   {missing}")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ WSI —Ñ–∞–π–ª–∞
    wsi_path = "wsi/19_ibd_mod_S037__20240822_091343.tiff"
    if not os.path.exists(wsi_path):
        print(f"‚ùå WSI —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {wsi_path}")
        return False
    
    print("‚úÖ –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã –Ω–∞–π–¥–µ–Ω—ã")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏
    import torch
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB
        print(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ GPU –ø–∞–º—è—Ç—å: {gpu_memory:.1f} GB")
        
        if gpu_memory < 8:
            config = {'batch_size': 8, 'max_workers': 2, 'name': 'Low Memory'}
        elif gpu_memory < 16:
            config = {'batch_size': 16, 'max_workers': 4, 'name': 'Balanced'}
        else:
            config = {'batch_size': 32, 'max_workers': 6, 'name': 'High Performance'}
    else:
        config = {'batch_size': 8, 'max_workers': 2, 'name': 'CPU Only'}
    
    print(f"‚öôÔ∏è  –í—ã–±—Ä–∞–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {config['name']}")
    print(f"   –ë–∞—Ç—á —Ä–∞–∑–º–µ—Ä: {config['batch_size']}")
    print(f"   –ü–æ—Ç–æ–∫–æ–≤: {config['max_workers']}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º pipeline
    pipeline = ImprovedWSIYOLOPipeline(
        model_paths=model_paths,
        patch_size=512,
        batch_size=config['batch_size'],
        max_workers=config['max_workers']
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ WSI...")
    results = pipeline.process_wsi(wsi_path, "results_improved_full")
    
    if 'error' in results:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {results['error']}")
        return False
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    predictions = results.get('predictions', [])
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
    print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ–ª—É—á–µ–Ω–æ: {len(predictions)}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º
    class_stats = {}
    for pred in predictions:
        class_name = pred.get('class_name', 'unknown')
        class_stats[class_name] = class_stats.get(class_name, 0) + 1
    
    print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º:")
    for class_name, count in class_stats.items():
        print(f"     {class_name}: {count}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É–ø—Ä–æ—â–µ–Ω–∏—è –ø–æ–ª–∏–≥–æ–Ω–æ–≤
    simplified_count = 0
    total_area_preserved = 0
    for pred in predictions:
        if 'simplification_metrics' in pred:
            simplified_count += 1
            total_area_preserved += pred['simplification_metrics'].get('area_preserved', 1.0)
    
    if simplified_count > 0:
        avg_area_preserved = total_area_preserved / simplified_count
        print(f"   –ü–æ–ª–∏–≥–æ–Ω–æ–≤ —É–ø—Ä–æ—â–µ–Ω–æ: {simplified_count}")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–ª–æ—â–∞–¥–∏: {avg_area_preserved:.1%}")
    
    print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: results_improved_full/")
    
    return True

if __name__ == "__main__":
    success = main()
    if success:
        print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print("   - –°—Ä–∞–≤–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º pipeline")
        print("   - –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
        print("   - –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥ –≤–∞—à–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ")
    else:
        print("\n‚ùå –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
        print("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∞–π–ª–æ–≤")
        print("   - –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –ø—É—Ç–µ–π")
        print("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU/CPU —Ä–µ—Å—É—Ä—Å–æ–≤")
